{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Speech Emotion Recognition - Train All Models\n",
    "\n",
    "Train **3 different models** on Google Colab with free GPU:\n",
    "1. **CNN** - Convolutional Neural Network\n",
    "2. **CNN-LSTM** - Hybrid model with temporal features\n",
    "3. **LSTM** - Recurrent network for sequential features\n",
    "\n",
    "**Steps:**\n",
    "1. Upload RAVDESS dataset\n",
    "2. Extract features\n",
    "3. Train all 3 models\n",
    "4. Compare results\n",
    "5. Download trained model files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa soundfile tqdm -q\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Dropout, Flatten,\n",
    "    BatchNormalization, GlobalAveragePooling2D,\n",
    "    LSTM, Bidirectional, Input, Reshape\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload RAVDESS Dataset\n",
    "\n",
    "**Option A:** Download from Kaggle using API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Download from Kaggle using API credentials\n",
    "# Enter your Kaggle username and API key below (from kaggle.com/settings ‚Üí API)\n",
    "\n",
    "KAGGLE_USERNAME = \"your_username_here\"  # <-- Replace with your Kaggle username\n",
    "KAGGLE_KEY = \"your_api_key_here\"        # <-- Replace with your API key\n",
    "\n",
    "# Create kaggle.json from credentials\n",
    "kaggle_creds = {\"username\": KAGGLE_USERNAME, \"key\": KAGGLE_KEY}\n",
    "with open(\"kaggle.json\", \"w\") as f:\n",
    "    json.dump(kaggle_creds, f)\n",
    "\n",
    "print(f\"‚úì Kaggle credentials set for user: {KAGGLE_USERNAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle and download dataset\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\n",
    "!unzip -q ravdess-emotional-speech-audio.zip -d data\n",
    "print(\"‚úì Dataset downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Upload ZIP manually (skip Kaggle entirely)\n",
    "# Uncomment the lines below if you prefer to upload your own dataset\n",
    "\n",
    "# from google.colab import files\n",
    "# print(\"Upload your RAVDESS archive.zip:\")\n",
    "# uploaded = files.upload()\n",
    "# !unzip -q archive.zip -d data\n",
    "# print(\"‚úì Dataset extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "!ls data/\n",
    "!ls data/ | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3\n",
    "N_MFCC = 40\n",
    "N_MELS = 128\n",
    "HOP_LENGTH = 512\n",
    "N_FFT = 2048\n",
    "\n",
    "EMOTIONS = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Store results for comparison\n",
    "results = {}\n",
    "\n",
    "print(\"‚úì Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(file_path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    \"\"\"Extract mel spectrogram for CNN/CNN-LSTM models.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "        max_len = sr * duration\n",
    "        if len(y) < max_len:\n",
    "            y = np.pad(y, (0, max_len - len(y)), mode='constant')\n",
    "        else:\n",
    "            y = y[:max_len]\n",
    "        \n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "        )\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        return mel_spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_combined_features(file_path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    \"\"\"Extract combined features for LSTM model.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "        max_len = sr * duration\n",
    "        if len(y) < max_len:\n",
    "            y = np.pad(y, (0, max_len - len(y)), mode='constant')\n",
    "        else:\n",
    "            y = y[:max_len]\n",
    "        \n",
    "        # MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "        \n",
    "        # Mel spectrogram stats\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_mean = np.mean(mel_spec_db, axis=1)\n",
    "        mel_std = np.std(mel_spec_db, axis=1)\n",
    "        \n",
    "        # Chroma\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        chroma_std = np.std(chroma, axis=1)\n",
    "        \n",
    "        # Spectral contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "        contrast_mean = np.mean(contrast, axis=1)\n",
    "        contrast_std = np.std(contrast, axis=1)\n",
    "        \n",
    "        # ZCR and RMS\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        rms = librosa.feature.rms(y=y)\n",
    "        \n",
    "        features = np.concatenate([\n",
    "            mfccs_mean, mfccs_std,\n",
    "            mel_mean, mel_std,\n",
    "            chroma_mean, chroma_std,\n",
    "            contrast_mean, contrast_std,\n",
    "            [np.mean(zcr), np.std(zcr)],\n",
    "            [np.mean(rms), np.std(rms)]\n",
    "        ])\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_ravdess_filename(filename):\n",
    "    \"\"\"Parse RAVDESS filename to extract emotion.\"\"\"\n",
    "    parts = filename.replace('.wav', '').split('-')\n",
    "    if len(parts) != 7:\n",
    "        return None\n",
    "    return {'emotion': parts[2], 'actor': parts[6]}\n",
    "\n",
    "print(\"‚úì Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ravdess_data(data_path, feature_type='mel'):\n",
    "    \"\"\"Load RAVDESS dataset with specified feature type.\"\"\"\n",
    "    features_list = []\n",
    "    labels = []\n",
    "    \n",
    "    # Find all Actor directories\n",
    "    actor_dirs = []\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for d in dirs:\n",
    "            if d.startswith('Actor_'):\n",
    "                actor_dirs.append(os.path.join(root, d))\n",
    "    \n",
    "    print(f\"Found {len(actor_dirs)} actor directories\")\n",
    "    \n",
    "    for actor_path in tqdm(actor_dirs, desc=f\"Extracting {feature_type} features\"):\n",
    "        wav_files = [f for f in os.listdir(actor_path) if f.endswith('.wav')]\n",
    "        \n",
    "        for wav_file in wav_files:\n",
    "            file_path = os.path.join(actor_path, wav_file)\n",
    "            file_info = parse_ravdess_filename(wav_file)\n",
    "            if file_info is None:\n",
    "                continue\n",
    "            \n",
    "            # Extract features based on type\n",
    "            if feature_type == 'mel':\n",
    "                feat = extract_mel_spectrogram(file_path)\n",
    "            else:\n",
    "                feat = extract_combined_features(file_path)\n",
    "            \n",
    "            if feat is None:\n",
    "                continue\n",
    "            \n",
    "            emotion_label = EMOTIONS.get(file_info['emotion'], 'unknown')\n",
    "            if emotion_label == 'unknown':\n",
    "                continue\n",
    "            \n",
    "            features_list.append(feat)\n",
    "            labels.append(emotion_label)\n",
    "    \n",
    "    X = np.array(features_list)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"Loaded {len(X)} samples, shape: {X.shape}\")\n",
    "    return X, y\n",
    "\n",
    "print(\"‚úì Data loader defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data (Both Feature Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mel spectrogram features (for CNN and CNN-LSTM)\n",
    "print(\"=\"*60)\n",
    "print(\"Loading MEL SPECTROGRAM features...\")\n",
    "print(\"=\"*60)\n",
    "X_mel, y = load_ravdess_data(DATA_PATH, feature_type='mel')\n",
    "\n",
    "print(f\"\\n‚úì Mel features: {X_mel.shape}\")\n",
    "print(f\"\\nEmotion distribution:\")\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined features (for LSTM)\n",
    "print(\"=\"*60)\n",
    "print(\"Loading COMBINED features for LSTM...\")\n",
    "print(\"=\"*60)\n",
    "X_combined, _ = load_ravdess_data(DATA_PATH, feature_type='combined')\n",
    "\n",
    "print(f\"\\n‚úì Combined features: {X_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Split for mel features (CNN, CNN-LSTM)\n",
    "X_mel_train, X_mel_test, y_train, y_test = train_test_split(\n",
    "    X_mel, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Split for combined features (LSTM)\n",
    "X_comb_train, X_comb_test, _, _ = train_test_split(\n",
    "    X_combined, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Normalize mel features\n",
    "X_mel_train_norm = (X_mel_train - X_mel_train.mean()) / (X_mel_train.std() + 1e-8)\n",
    "X_mel_test_norm = (X_mel_test - X_mel_test.mean()) / (X_mel_test.std() + 1e-8)\n",
    "\n",
    "# Add channel dimension for CNN\n",
    "X_mel_train_cnn = X_mel_train_norm[..., np.newaxis]\n",
    "X_mel_test_cnn = X_mel_test_norm[..., np.newaxis]\n",
    "\n",
    "# Normalize combined features with scaler\n",
    "scaler = StandardScaler()\n",
    "X_comb_train_norm = scaler.fit_transform(X_comb_train)\n",
    "X_comb_test_norm = scaler.transform(X_comb_test)\n",
    "\n",
    "# Reshape for LSTM (samples, timesteps, features)\n",
    "X_comb_train_lstm = X_comb_train_norm.reshape(X_comb_train_norm.shape[0], 1, X_comb_train_norm.shape[1])\n",
    "X_comb_test_lstm = X_comb_test_norm.reshape(X_comb_test_norm.shape[0], 1, X_comb_test_norm.shape[1])\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_mel_train)}\")\n",
    "print(f\"Test samples: {len(X_mel_test)}\")\n",
    "print(f\"\\nCNN input shape: {X_mel_train_cnn.shape[1:]}\")\n",
    "print(f\"LSTM input shape: {X_comb_train_lstm.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define All Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"CNN model for mel spectrogram input.\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cnn_lstm_model(input_shape, num_classes):\n",
    "    \"\"\"CNN-LSTM hybrid model.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    shape = x.shape\n",
    "    x = Reshape((shape[1], shape[2] * shape[3]))(x)\n",
    "    \n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    \"\"\"LSTM model for 1D features.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(256, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(64),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "print(\"‚úì All model architectures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train model and return results.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name.upper()} Model\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\n{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_pred_labels = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "    y_true_labels = label_encoder.inverse_transform(np.argmax(y_test, axis=1))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'accuracy': accuracy,\n",
    "        'loss': loss,\n",
    "        'y_pred': y_pred_labels,\n",
    "        'y_true': y_true_labels\n",
    "    }\n",
    "\n",
    "print(\"‚úì Training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "cnn_model = build_cnn_model(X_mel_train_cnn.shape[1:], num_classes)\n",
    "results['cnn'] = train_and_evaluate(\n",
    "    cnn_model, 'CNN',\n",
    "    X_mel_train_cnn, X_mel_test_cnn, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN-LSTM\n",
    "cnn_lstm_model = build_cnn_lstm_model(X_mel_train_cnn.shape[1:], num_classes)\n",
    "results['cnn_lstm'] = train_and_evaluate(\n",
    "    cnn_lstm_model, 'CNN-LSTM',\n",
    "    X_mel_train_cnn, X_mel_test_cnn, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM\n",
    "lstm_model = build_lstm_model(X_comb_train_lstm.shape[1:], num_classes)\n",
    "results['lstm'] = train_and_evaluate(\n",
    "    lstm_model, 'LSTM',\n",
    "    X_comb_train_lstm, X_comb_test_lstm, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['CNN', 'CNN-LSTM', 'LSTM'],\n",
    "    'Test Accuracy': [\n",
    "        f\"{results['cnn']['accuracy']:.4f}\",\n",
    "        f\"{results['cnn_lstm']['accuracy']:.4f}\",\n",
    "        f\"{results['lstm']['accuracy']:.4f}\"\n",
    "    ],\n",
    "    'Test Loss': [\n",
    "        f\"{results['cnn']['loss']:.4f}\",\n",
    "        f\"{results['cnn_lstm']['loss']:.4f}\",\n",
    "        f\"{results['lstm']['loss']:.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "print(f\"\\nüèÜ Best Model: {best_model.upper()} with {results[best_model]['accuracy']:.4f} accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, (name, res) in enumerate(results.items()):\n",
    "    # Accuracy\n",
    "    axes[0, idx].plot(res['history'].history['accuracy'], label='Train')\n",
    "    axes[0, idx].plot(res['history'].history['val_accuracy'], label='Val')\n",
    "    axes[0, idx].set_title(f'{name.upper()} Accuracy')\n",
    "    axes[0, idx].set_xlabel('Epoch')\n",
    "    axes[0, idx].set_ylabel('Accuracy')\n",
    "    axes[0, idx].legend()\n",
    "    axes[0, idx].grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    axes[1, idx].plot(res['history'].history['loss'], label='Train')\n",
    "    axes[1, idx].plot(res['history'].history['val_loss'], label='Val')\n",
    "    axes[1, idx].set_title(f'{name.upper()} Loss')\n",
    "    axes[1, idx].set_xlabel('Epoch')\n",
    "    axes[1, idx].set_ylabel('Loss')\n",
    "    axes[1, idx].legend()\n",
    "    axes[1, idx].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_models_training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "for idx, (name, res) in enumerate(results.items()):\n",
    "    cm = confusion_matrix(res['y_true'], res['y_pred'], labels=label_encoder.classes_)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    axes[idx].set_title(f'{name.upper()} Confusion Matrix')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_models_confusion_matrices.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "for name, res in results.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name.upper()} Classification Report\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(classification_report(res['y_true'], res['y_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save each model\n",
    "for name, res in results.items():\n",
    "    # Save model\n",
    "    res['model'].save(f'models/emotion_model_{name}.keras')\n",
    "    print(f\"‚úì Saved: models/emotion_model_{name}.keras\")\n",
    "    \n",
    "    # Save config\n",
    "    if name == 'lstm':\n",
    "        input_shape = X_comb_train_lstm.shape[1:]\n",
    "    else:\n",
    "        input_shape = X_mel_train_cnn.shape[1:]\n",
    "    \n",
    "    config = {\n",
    "        'model_type': name,\n",
    "        'input_shape': input_shape,\n",
    "        'num_classes': num_classes,\n",
    "        'accuracy': float(res['accuracy'])\n",
    "    }\n",
    "    with open(f'models/emotion_model_{name}_config.pkl', 'wb') as f:\n",
    "        pickle.dump(config, f)\n",
    "    print(f\"‚úì Saved: models/emotion_model_{name}_config.pkl\")\n",
    "\n",
    "# Save label encoder (same for all)\n",
    "with open('models/emotion_model_cnn_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "with open('models/emotion_model_cnn_lstm_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "with open('models/emotion_model_lstm_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(\"‚úì Saved: label encoders for all models\")\n",
    "\n",
    "# Save scaler (for LSTM)\n",
    "with open('models/emotion_model_cnn_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(StandardScaler().fit([[0]]), f)  # Dummy for CNN\n",
    "with open('models/emotion_model_cnn_lstm_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(StandardScaler().fit([[0]]), f)  # Dummy for CNN-LSTM\n",
    "with open('models/emotion_model_lstm_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)  # Real scaler for LSTM\n",
    "print(\"‚úì Saved: scalers for all models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All models saved!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved files\n",
    "!ls -la models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Download All Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all models for easy download\n",
    "!zip -r trained_models.zip models/\n",
    "print(\"‚úì Created trained_models.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the zip file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading all trained models...\")\n",
    "print(\"Extract to your local: SpeechEmotionRecognition/models/ folder\")\n",
    "print()\n",
    "\n",
    "files.download('trained_models.zip')\n",
    "print(\"\\n‚úì Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also download plots\n",
    "files.download('all_models_training_history.png')\n",
    "files.download('all_models_confusion_matrices.png')\n",
    "print(\"‚úì Plots downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Next Steps\n",
    "\n",
    "After downloading `trained_models.zip`:\n",
    "\n",
    "1. **Extract to your local project:**\n",
    "   ```bash\n",
    "   cd ~/Downloads/Sem-1/SpeechEmotionRecognition\n",
    "   unzip ~/Downloads/trained_models.zip\n",
    "   ```\n",
    "\n",
    "2. **Your models folder should have:**\n",
    "   ```\n",
    "   models/\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn.keras\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_config.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_label_encoder.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_scaler.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_lstm.keras\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_lstm_config.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_lstm_label_encoder.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_cnn_lstm_scaler.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_lstm.keras\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_lstm_config.pkl\n",
    "   ‚îú‚îÄ‚îÄ emotion_model_lstm_label_encoder.pkl\n",
    "   ‚îî‚îÄ‚îÄ emotion_model_lstm_scaler.pkl\n",
    "   ```\n",
    "\n",
    "3. **Run the web app:**\n",
    "   ```bash\n",
    "   source audioML/bin/activate\n",
    "   python app.py\n",
    "   ```\n",
    "\n",
    "4. **Open browser:** http://localhost:5000\n",
    "\n",
    "The app uses CNN by default. To use a different model, modify `voice_assistant.py`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
