{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Speech Emotion Recognition - Training Notebook\n",
    "\n",
    "Train the emotion recognition model on Google Colab with free GPU.\n",
    "\n",
    "**Steps:**\n",
    "1. Upload RAVDESS dataset\n",
    "2. Extract features\n",
    "3. Train CNN model\n",
    "4. Download trained model files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa soundfile tqdm -q\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Dense, Dropout, Flatten,\n",
    "    BatchNormalization, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload RAVDESS Dataset\n",
    "\n",
    "**Option A:** Upload from Kaggle (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Download from Kaggle\n",
    "# First, upload your kaggle.json file\n",
    "from google.colab import files\n",
    "print(\"Upload your kaggle.json file:\")\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle and download dataset\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\n",
    "!unzip -q ravdess-emotional-speech-audio.zip -d data\n",
    "print(\"‚úì Dataset downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Upload ZIP manually\n",
    "# from google.colab import files\n",
    "# print(\"Upload your RAVDESS archive.zip:\")\n",
    "# uploaded = files.upload()\n",
    "# !unzip -q archive.zip -d data\n",
    "# print(\"‚úì Dataset extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "!ls data/\n",
    "!ls data/ | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data\"  # Adjust if needed based on extracted structure\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3\n",
    "N_MELS = 128\n",
    "HOP_LENGTH = 512\n",
    "N_FFT = 2048\n",
    "\n",
    "EMOTIONS = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"‚úì Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(file_path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    \"\"\"Extract mel spectrogram from audio file.\"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "        \n",
    "        # Pad or truncate to fixed length\n",
    "        max_len = sr * duration\n",
    "        if len(y) < max_len:\n",
    "            y = np.pad(y, (0, max_len - len(y)), mode='constant')\n",
    "        else:\n",
    "            y = y[:max_len]\n",
    "        \n",
    "        # Extract mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "        )\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        return mel_spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_ravdess_filename(filename):\n",
    "    \"\"\"Parse RAVDESS filename to extract emotion.\"\"\"\n",
    "    parts = filename.replace('.wav', '').split('-')\n",
    "    if len(parts) != 7:\n",
    "        return None\n",
    "    return {\n",
    "        'emotion': parts[2],\n",
    "        'actor': parts[6]\n",
    "    }\n",
    "\n",
    "print(\"‚úì Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ravdess_data(data_path):\n",
    "    \"\"\"Load RAVDESS dataset and extract features.\"\"\"\n",
    "    features_list = []\n",
    "    labels = []\n",
    "    \n",
    "    # Find all Actor directories\n",
    "    actor_dirs = []\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for d in dirs:\n",
    "            if d.startswith('Actor_'):\n",
    "                actor_dirs.append(os.path.join(root, d))\n",
    "    \n",
    "    print(f\"Found {len(actor_dirs)} actor directories\")\n",
    "    \n",
    "    for actor_path in tqdm(actor_dirs, desc=\"Processing actors\"):\n",
    "        wav_files = [f for f in os.listdir(actor_path) if f.endswith('.wav')]\n",
    "        \n",
    "        for wav_file in wav_files:\n",
    "            file_path = os.path.join(actor_path, wav_file)\n",
    "            \n",
    "            # Parse filename\n",
    "            file_info = parse_ravdess_filename(wav_file)\n",
    "            if file_info is None:\n",
    "                continue\n",
    "            \n",
    "            # Extract features\n",
    "            mel_spec = extract_mel_spectrogram(file_path)\n",
    "            if mel_spec is None:\n",
    "                continue\n",
    "            \n",
    "            # Get emotion label\n",
    "            emotion_label = EMOTIONS.get(file_info['emotion'], 'unknown')\n",
    "            if emotion_label == 'unknown':\n",
    "                continue\n",
    "            \n",
    "            features_list.append(mel_spec)\n",
    "            labels.append(emotion_label)\n",
    "    \n",
    "    X = np.array(features_list)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"\\nLoaded {len(X)} samples\")\n",
    "    print(f\"Feature shape: {X.shape}\")\n",
    "    print(f\"\\nEmotion distribution:\")\n",
    "    print(pd.Series(y).value_counts())\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "print(\"‚úì Data loader defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and extract features\n",
    "print(\"Loading RAVDESS dataset...\")\n",
    "X, y = load_ravdess_data(DATA_PATH)\n",
    "print(f\"\\n‚úì Features extracted: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"Classes: {label_encoder.classes_}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Normalize\n",
    "X_train = (X_train - X_train.mean()) / (X_train.std() + 1e-8)\n",
    "X_test = (X_test - X_test.mean()) / (X_test.std() + 1e-8)\n",
    "\n",
    "# Add channel dimension for CNN\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Input shape: {X_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"Build CNN model for emotion recognition.\"\"\"\n",
    "    model = Sequential([\n",
    "        # First Conv Block\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fourth Conv Block\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_cnn_model(X_train.shape[1:], num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = label_encoder.inverse_transform(np.argmax(y_test, axis=1))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history.history['accuracy'], label='Train')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history.history['loss'], label='Train')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=label_encoder.classes_)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model Files\n",
    "\n",
    "**Download these 3 files to your local `models/` folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save('models/emotion_model_cnn.keras')\n",
    "print(\"‚úì Model saved: models/emotion_model_cnn.keras\")\n",
    "\n",
    "# Save label encoder\n",
    "with open('models/emotion_model_cnn_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(\"‚úì Label encoder saved: models/emotion_model_cnn_label_encoder.pkl\")\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'model_type': 'cnn',\n",
    "    'input_shape': X_train.shape[1:],\n",
    "    'num_classes': num_classes\n",
    "}\n",
    "with open('models/emotion_model_cnn_config.pkl', 'wb') as f:\n",
    "    pickle.dump(config, f)\n",
    "print(\"‚úì Config saved: models/emotion_model_cnn_config.pkl\")\n",
    "\n",
    "# Save a dummy scaler (not used for CNN but needed for compatibility)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit([[0]])  # Dummy fit\n",
    "with open('models/emotion_model_cnn_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"‚úì Scaler saved: models/emotion_model_cnn_scaler.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All model files saved!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all model files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading model files...\")\n",
    "print(\"Save these to your local: SpeechEmotionRecognition/models/ folder\")\n",
    "print()\n",
    "\n",
    "files.download('models/emotion_model_cnn.keras')\n",
    "files.download('models/emotion_model_cnn_label_encoder.pkl')\n",
    "files.download('models/emotion_model_cnn_config.pkl')\n",
    "files.download('models/emotion_model_cnn_scaler.pkl')\n",
    "\n",
    "print(\"\\n‚úì All files downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also download the plots\n",
    "files.download('training_history.png')\n",
    "files.download('confusion_matrix.png')\n",
    "print(\"‚úì Plots downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "After downloading the model files:\n",
    "\n",
    "1. **Copy files to your local project:**\n",
    "   ```\n",
    "   SpeechEmotionRecognition/\n",
    "   ‚îî‚îÄ‚îÄ models/\n",
    "       ‚îú‚îÄ‚îÄ emotion_model_cnn.keras\n",
    "       ‚îú‚îÄ‚îÄ emotion_model_cnn_label_encoder.pkl\n",
    "       ‚îú‚îÄ‚îÄ emotion_model_cnn_config.pkl\n",
    "       ‚îî‚îÄ‚îÄ emotion_model_cnn_scaler.pkl\n",
    "   ```\n",
    "\n",
    "2. **Run the web app locally:**\n",
    "   ```bash\n",
    "   cd SpeechEmotionRecognition\n",
    "   source audioML/bin/activate\n",
    "   python app.py\n",
    "   ```\n",
    "\n",
    "3. **Open browser:** http://localhost:5000"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
